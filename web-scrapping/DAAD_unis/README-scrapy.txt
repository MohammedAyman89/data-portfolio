# ğŸ¯ DAAD University Programs Scraper (Scrapy)

This project is a professional **Scrapy spider** for scraping international university programs from the official DAAD.de API. It shows **real-world API scraping** with custom headers, JSON parsing, and CSV export.

---

## ğŸš€ Features

âœ… Uses Scrapy framework for powerful, production-grade crawling  
âœ… Custom realistic browser headers and cookies  
âœ… GET requests with complex parameters  
âœ… Handles JSON API responses  
âœ… Extracts multiple program fields into structured CSV  
âœ… Includes polite scraping with download delay  
âœ… CSV export via Scrapy FEEDS

---

## ğŸ—ºï¸ Data Source

**DAAD (German Academic Exchange Service) International Programmes Search API**  

- Example API Endpoint:
https://www2.daad.de/deutschland/studienangebote/international-programmes/api/solr/en/search.json

- Filtered for:
  - Bachelor's degree (degree[]=1)
  - English language (lang[]=4)

---

## ğŸ§¾ Extracted Fields

âœ”ï¸ program_ID  
âœ”ï¸ name (courseNameShort)  
âœ”ï¸ subject  
âœ”ï¸ city  
âœ”ï¸ language(s)  
âœ”ï¸ duration  
âœ”ï¸ fees  

---

## ğŸ“‚ Example Output (DAAD.csv)

| program_ID | name                          | subject         | city     | language  | duration | fees        |
|------------|------------------------------|-----------------|----------|-----------|----------|-------------|
| 123456     | Computer Science (BSc)       | Computer Science| Berlin   | English   | 3 years  | â‚¬1,000/year |
| 654321     | Mechanical Engineering (BSc) | Engineering     | Munich   | English   | 3 years  | â‚¬1,500/year |

---

## âš™ï¸ Project Structure

DAAD-scrapy-version.py/
DAAD-scrapy.csv/
README-scrapy/

---

## ğŸ› ï¸ Requirements

- Python 3.8+
- Scrapy

Install Scrapy if needed:

```bash
pip install scrapy

how to run:
python daad_spider.py

âœ… It will:

Send GET requests with custom headers

Parse JSON responses

Collect fields

Save the structured data to DAAD.csv automatically

ğŸ’¡ How It Works
âœ”ï¸ Uses Scrapy's request/response pipeline
âœ”ï¸ Sets realistic browser headers and cookies
âœ”ï¸ Parses JSON via response.json()
âœ”ï¸ Extracts desired fields
âœ”ï¸ Exports to CSV using Scrapy's FEEDS

âœ… Highlights of the Code
User-Agent and headers mimic a real browser

Handles API GET params (degree type, language, offset)

Can be expanded for pagination easily

Clean CSV output ready for analysis

ğŸŒŸ Why Use Scrapy Here?
âœ… Designed for large-scale scraping
âœ… Built-in throttling and delays
âœ… Easy header and cookie management
âœ… Auto CSV export via FEEDS
âœ… Great for production-quality scrapers

âš ï¸ Ethical Note
Always respect the websiteâ€™s terms of service and robots.txt.

Use polite scraping: delays, user-agent rotation, etc.

This project includes a download delay and static headers to avoid overloading the server.

ğŸ‘¤ Author
Mohammed Ayman Aly - Freelance Data & Web Scraping Specialist

